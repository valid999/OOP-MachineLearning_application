{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Managing GPU Resources with pytorch \n",
    "# when working with GPU, it's essential to manage memeory efficiently. Pytorch provides a context manager for handling device-specific operations. \n",
    "\n",
    "import torch \n",
    "\n",
    "# Ensures computations are done on the GPU if available \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model = torch.nn.Linear(10, 1).to(device)\n",
    "    input_data = torch.randn(5, 10).to(device)\n",
    "    output = model(input_data)\n",
    "    print(output)\n",
    "\n",
    "# The with block ensures no gradients are tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 5.042034 seconds\n"
     ]
    }
   ],
   "source": [
    "# Traking Training time \n",
    "# Monitoring the time taken for each epoch or operation is a common requirement in ML pipelines. A custom manager can help.\n",
    "\n",
    "import time \n",
    "\n",
    "\n",
    "class Timer: \n",
    "    def __enter__(self): \n",
    "        self.start = time.time()\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback): \n",
    "        self.end = time.time()\n",
    "        print(f\"Elapsed time: {self.end - self.start:2f} seconds\")\n",
    "\n",
    "\n",
    "# Use during model training \n",
    "with Timer(): \n",
    "    for epoch in range(5): \n",
    "        time.sleep(1)\n",
    "# Use case: measures the duration of training steps or operations for performance monitoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Managing Tensorflow Session (Pre-TF 2.0)\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "with tf.Sessions() as session: \n",
    "    x = tf.constant(2)\n",
    "    y = tf.constant(3)\n",
    "    z = x + y \n",
    "    result  = session.run(z)\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "# The session is automatically closed when the block ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handling Temporary Directories for Data Caching \n",
    "\n",
    "import tempfile \n",
    "import os \n",
    "\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir: \n",
    "    print(f\"Using temporary directory: {temp_dir}\")\n",
    "    # Simulate writing a large dataset to temporary storage \n",
    "    temp_file = os.path.join(temp_dir, 'data.text')\n",
    "    with open(temp_file, 'w') as f: \n",
    "        f.write(\"Temporary data\")\n",
    "    print(f\"Data written to {temp_file}\")\n",
    "\n",
    "# The temporary directory and its contents are cleaned up automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentLogger: \n",
    "    def __init__(self, log_file):\n",
    "        self.log_file = log_file \n",
    "    \n",
    "    \n",
    "    def __enter__(self): \n",
    "        self.file = open(self.log_file, 'w')\n",
    "        self.file.write(\"Experiment Start\\n\")\n",
    "        return self.file \n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback): \n",
    "        self.file.write(\"Experiment End\\n\")\n",
    "        self.file.close()\n",
    "\n",
    "\n",
    "# LOg experiment details \n",
    "with ExperimentLogger(\"experiement.log\") as log: \n",
    "    log.write(\"Learning Rate: 0.01\\n\")\n",
    "    log.write(\"Batch size: 32]\\n\")\n",
    "    log.write(\"Model: ResNet\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4\n"
     ]
    }
   ],
   "source": [
    "class EarlyStopping: \n",
    "    def __init__(self, patience=3): \n",
    "        self.patience = patience \n",
    "        self.counter = 0 \n",
    "        self.counter = 0 \n",
    "        self.best_loss = float('inf')\n",
    "    \n",
    "    def __enter__(self): \n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback): \n",
    "        return self \n",
    "    \n",
    "    \n",
    "    def __check(self, current_loss): \n",
    "        if current_loss < self.best_loss: \n",
    "            self.best_loss = current_loss\n",
    "            self.counter = 0 \n",
    "        else: \n",
    "            self.counter  += 1 \n",
    "            if self.counter >= self.patience: \n",
    "                print(\"early stopping triggered!\")\n",
    "                return True \n",
    "        return False \n",
    "\n",
    "# Example usage during training \n",
    "with EarlyStopping(patience=2) as early_stopper: \n",
    "    losses  = [0.4, 0.35, 0.36, 0.37]\n",
    "    for loss in losses: \n",
    "        print(f\"Loss: {loss}\")\n",
    "        if early_stopper.check(loss): \n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolo_object",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
